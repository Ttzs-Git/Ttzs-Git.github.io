<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Ttzs">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
    <!--- Seo Part-->
    
    <link rel="canonical" href="https://ttzs-git.github.io/2025/09/25/多模态大模型入门指南-阅读提问/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
    
    
        
        <meta name="description" content="Ttzs.">
<meta property="og:type" content="article">
<meta property="og:title" content="多模态大模型入门指南-阅读提问">
<meta property="og:url" content="https://ttzs-git.github.io/2025/09/25/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97-%E9%98%85%E8%AF%BB%E6%8F%90%E9%97%AE/index.html">
<meta property="og:site_name" content="静思轩">
<meta property="og:description" content="Ttzs.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ttzs-git.github.io/images/redefine-og.webp">
<meta property="article:published_time" content="2025-09-25T05:00:02.000Z">
<meta property="article:modified_time" content="2025-10-04T11:30:48.972Z">
<meta property="article:author" content="Ttzs">
<meta property="article:tag" content="综述">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ttzs-git.github.io/images/redefine-og.webp">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="../../../../images/pi2.png" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="../../../../images/pi2.png">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="../../../../images/pi2.png">
    <!--- Page Info-->
    
    <title>
        
            多模态大模型入门指南-阅读提问 | 静思轩
        
    </title>

    
<link rel="stylesheet" href="fonts/Chillax/chillax.css">


    <!--- Inject Part-->
    

    
<link rel="stylesheet" href="../../../../css/style.css">


    
        
<link rel="stylesheet" href="css/build/tailwind.css">

    

    
<link rel="stylesheet" href="fonts/GeistMono/geist-mono.css">

    
<link rel="stylesheet" href="fonts/Geist/geist.css">

    <!--- Font Part-->
    
        <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&family=Ma+Shan+Zheng&family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap" rel="stylesheet">
    
    
    
        <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&family=Ma+Shan+Zheng&family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap" rel="stylesheet">
    
    
        <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap" rel="stylesheet">
    
    
    

    <script id="hexo-configurations">
    window.config = {"hostname":"ttzs-git.github.io","root":"/","language":"zh-CN","path":"search.xml"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true,"delete_mask":false,"title_alignment":"left","headings_top_spacing":{"h1":"5rem","h2":"4rem","h3":"2.8rem","h4":"2.5rem","h5":"2.2rem","h6":"2rem"}},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","highlight_theme":{"light":"github","dark":"vs2015"},"font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":true,"expand":true,"init_open":true},"copyright":{"enable":true,"default":"cc_by_nc_sa"},"lazyload":true,"pangu_js":false,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null,"default_mode":"light"},"global":{"fonts":{"chinese":{"enable":true,"family":"Ma Shan Zheng","url":"https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&family=Ma+Shan+Zheng&family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap"},"english":{"enable":true,"family":"JetBrains Mono","url":"https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap"},"title":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://cn.vercount.one/js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"preloader":{"enable":false,"custom_message":null},"open_graph":{"enable":true,"image":"/images/redefine-og.webp","description":"Ttzs."},"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/to.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"静思轩","subtitle":{"text":["Computer","Math","Artificial Intelligence","How to survive under AI background"],"hitokoto":{"enable":true,"show_author":true,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":true,"family":"Ma Shan Zheng","url":"https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&family=Ma+Shan+Zheng&family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap"},"social_links":{"enable":true,"style":"default","links":{"github":"https://github.com/Ttzs-Git","instagram":null,"zhihu":null,"twitter":null,"email":"ttzsgit@gmail.com","luogu":"https://www.luogu.com.cn/user/1758651"},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null,"lrc":null}]},"mermaid":{"enable":false,"version":"11.4.1"}},"version":"2.8.2","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"width":{"home":"1200px","pages":"1000px"},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Tags":{"path":"/tags","icon":"fa-solid fa-tags"},"ShuoShuo":{"icon":"fa-solid fa-comment-dots","path":"/shuoshuo"},"书签":{"icon":"fa-solid fa-bookmark","path":"/bookmarks"},"Links":{"icon":"fa-regular fa-link","submenus":{"Github":"https://github.com/Ttzs-Git","知乎":"https://www.zhihu.com/people/you-shi-bi-you-de-58","B站":"https://space.bilibili.com/3546821297179560?spm_id_from=333.1007.0.0"}}},"search":{"enable":true,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur","bookmarks_column":3},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"show_on_mobile":true,"links":{"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Gallery":{"path":"/masonry","icon":"fa-solid fa-image"},"Tags":{"path":"/tags","icon":"fa-regular fa-tags"},"Bookmarks":{"path":"/bookmarks","icon":"fa-solid fa-bookmark"}}},"article_date_format":"auto","excerpt_length":200,"categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2025/03/26 19:08:00"};
    window.lang_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
    window.data = {"masonry":true};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="fontawesome/brands.min.css">

    
<link rel="stylesheet" href="fontawesome/solid.min.css">

    
<link rel="stylesheet" href="fontawesome/regular.min.css">

    
    
        
<link rel="stylesheet" href="fontawesome/light.min.css">

    
    
    
<meta name="generator" content="Hexo 7.3.0"></head>



<body>
	<div class="progress-bar-container">
	

	
	<span class="pjax-progress-bar"></span>
	<!--        <span class="swup-progress-icon">-->
	<!--            <i class="fa-solid fa-circle-notch fa-spin"></i>-->
	<!--        </span>-->
	
</div>

<main class="page-container" id="swup">

	

	<div class="main-content-container flex flex-col justify-between min-h-dvh">
		<div class="main-content-header">
			<header class="navbar-container px-6 md:px-12">
    <div class="navbar-content transition-navbar ">
        <div class="left">
            
                <a class="logo-image h-8 w-8 sm:w-10 sm:h-10 mr-3" href="/">
                    <img src="../../../../images/pi1.png" class="w-full h-full rounded-sm">
                </a>
            
            <a class="logo-title" href="/">
                
                静思轩
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="../../../../index.html"
                                        >
                                    <i class="fa-regular fa-house fa-fw"></i>
                                    首页
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="../../../../archives"
                                        >
                                    <i class="fa-regular fa-archive fa-fw"></i>
                                    归档
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="../../../../tags"
                                        >
                                    <i class="fa-solid fa-tags fa-fw"></i>
                                    标签
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="../../../../shuoshuo"
                                        >
                                    <i class="fa-solid fa-comment-dots fa-fw"></i>
                                    说说
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="../../../../bookmarks"
                                        >
                                    <i class="fa-solid fa-bookmark fa-fw"></i>
                                    书签
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown"
                                   href="#"
                                        onClick=&#34;return false;&#34;>
                                    <i class="fa-regular fa-link fa-fw"></i>
                                    链接
                                    <i class="fa-solid fa-chevron-down fa-fw"></i>
                                </a>

                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://github.com/Ttzs-Git">
                                                    GITHUB
                                                </a>
                                            </li>
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://www.zhihu.com/people/you-shi-bi-you-de-58">
                                                    知乎
                                                </a>
                                            </li>
                                        
                                            <li>
                                                <a target="_blank" rel="noopener" href="https://space.bilibili.com/3546821297179560?spm_id_from=333.1007.0.0">
                                                    B站
                                                </a>
                                            </li>
                                        
                                    </ul>
                                
                            </li>
                    
                    
                        <li class="navbar-item search search-popup-trigger">
                            <i class="fa-solid fa-magnifying-glass"></i>
                        </li>
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i>
                    </div>
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile sheet -->
    <div class="navbar-drawer h-dvh w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between">
        <ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start">
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="../../../../index.html"
                        >
                            <span>
                                首页
                            </span>
                            
                                <i class="fa-regular fa-house fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="../../../../archives"
                        >
                            <span>
                                归档
                            </span>
                            
                                <i class="fa-regular fa-archive fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="../../../../tags"
                        >
                            <span>
                                标签
                            </span>
                            
                                <i class="fa-solid fa-tags fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="../../../../shuoshuo"
                        >
                            <span>
                                说说
                            </span>
                            
                                <i class="fa-solid fa-comment-dots fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="../../../../bookmarks"
                        >
                            <span>
                                书签
                            </span>
                            
                                <i class="fa-solid fa-bookmark fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item-sub text-base my-1.5 flex flex-col w-full">
                        
                        <div class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary cursor-pointer text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                             navbar-data-toggle="submenu-Links"
                        >
                            <span>
                                链接
                            </span>
                            
                                <i class="fa-solid fa-chevron-right fa-sm fa-fw transition-all"></i>
                            
                        </div>
                        

                        
                            <div class="flex-col items-start px-2 py-2 hidden" data-target="submenu-Links">
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://github.com/Ttzs-Git">GITHUB</a>
                                    </div>
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://www.zhihu.com/people/you-shi-bi-you-de-58">知乎</a>
                                    </div>
                                
                                    <div class="drawer-navbar-item text-base flex flex-col justify-center items-start hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                        <a class=" text-third-text-color text-xl"
                                           target="_blank" rel="noopener" href="https://space.bilibili.com/3546821297179560?spm_id_from=333.1007.0.0">B站</a>
                                    </div>
                                
                            </div>
                        
                    </li>
            

            
            
                
                    
                    
                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full active"
                           href="../../../../masonry"
                        >
                            <span>Gallery</span>
                            <i class="fa-solid fa-image fa-sm fa-fw"></i>
                        </a>
                    </li>
                
                    
                    
                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full active"
                           href="../../../../bookmarks"
                        >
                            <span>Bookmarks</span>
                            <i class="fa-solid fa-bookmark fa-sm fa-fw"></i>
                        </a>
                    </li>
                
            
        </ul>

        <div class="statistics flex justify-around my-2.5">
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="../../../../tags">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">10</div>
        <div class="label text-third-text-color text-sm">标签</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="../../../../categories">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">0</div>
        <div class="label text-third-text-color text-sm">分类</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="../../../../archives">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">16</div>
        <div class="label text-third-text-color text-sm">文章</div>
    </a>
</div>
    </div>

    <div class="window-mask"></div>

</header>


		</div>

		<div class="main-content-body transition-fade-up">
			

			<div class="main-content">
				<div class="post-page-container flex relative justify-between box-border w-full h-full">
	<div class="article-content-container">

		<div class="article-title relative w-full">
			
			<div class="w-full flex items-center pt-6 justify-start">
				<h1 class="article-title-regular text-second-text-color tracking-tight text-4xl md:text-6xl font-semibold px-2 sm:px-6 md:px-8 py-3">多模态大模型入门指南-阅读提问</h1>
			</div>
			
		</div>

		
		<div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8">
			<div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
				<img src="../../../../images/ttzs.jpg">
			</div>
			<div class="info flex flex-col justify-between">
				<div class="author flex items-center">
					<span class="name text-default-text-color text-lg font-semibold">Ttzs</span>
					
					<span class="author-label ml-1.5 text-xs px-2 py-0.5 rounded-small text-third-text-color border border-shadow-color-1">Lv3</span>
					
				</div>
				<div class="meta-info">
					<div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2025-09-25 13:02</span>
        <span class="mobile">2025-09-25 13:02</span>
        <span class="hover-info">创建</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2025-10-04 19:30:48</span>
            <span class="mobile">2025-10-04 19:30:48</span>
            <span class="hover-info">更新</span>
        </span>
    

    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="../../../../tags/%E7%BB%BC%E8%BF%B0/">综述</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>10.5k 字</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>38 分钟</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

				</div>
			</div>
		</div>
		

		


		<div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8">
			<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文是我在初步了解多模态大模型的过程中，结合博客阅读与GPT辅助理解后整理的文档。阅读本文档之前，您可以通过阅读第二部分的问题清单，判断您是否对于这些问题清楚</p>
<h1 id="问题清单"><a href="#问题清单" class="headerlink" title="问题清单"></a>问题清单</h1><p>下面的问题顺序是我阅读博客跟从GPT的对话中询问的问题，所以我是按照时间顺序整理的。因为我对于MMLLMs和LLM其实都不是很了解，所以会问很多基础问题、方法论问题以及抽象哲学问题。由于是问题的整理，所以在更高层面的问题会对小问题进行合并。<br>注意: 问题的颜色分类</p>
<blockquote>
<p>🔹 <strong>基础问题（入门级）</strong><br>   🔸 <strong>方法论问题（中阶）</strong><br>   🔺 <strong>抽象与哲学问题（高阶）</strong></p>
</blockquote>
<ol>
<li>🔹 是否可以认为传统 AI 更关注视觉、文本、图像等模态，而较少涉及如无线信号、语音、生理信号等多样化的感知模态？</li>
<li>🔹 信号的模态是不是比视觉&#x2F;文本&#x2F;图像更多样？</li>
<li>🔹 文中提到的 benchmark 是什么？</li>
<li>🔹 单模态基础模型是否只包括文字到文字的任务（如语言模型），还是也涵盖音频到音频、图像到图像等同模态映射任务？</li>
<li>🔸 Seq2Seq 模型与信号到信号（Signal-to-Signal）建模在本质上有什么区别？</li>
<li>🔸 Seq2Seq 框架下具体任务有哪些？</li>
<li>🔸 建模范式（Modeling Paradigms）可以如何划分？</li>
<li>🔺 能否更系统地抽象出不同模型思维方式或归纳假设之间的差异？</li>
<li>🔺常见的模型抽象有哪些？</li>
<li>🔺 是否存在比现有范式更高阶的抽象方式</li>
<li>🔸 多模态大模型（MM-LLM）可以从哪些维度进行系统级分类？</li>
<li>🔹 LLM 的 zero-shot 和 ICL 是什么？</li>
<li>🔹 LLM 中的预训练和指令微调分别是什么？</li>
<li>🔹 MMLLM 中输入和输出的 projector以及 LLM backbone 是什么？</li>
<li>🔹 ViT 中的 patch 是什么？图像被划分成 patch 后如何转化为 embedding？这种过程是否类似卷积？如果 patch 过大会不会丢失空间位置信息？</li>
<li>🔹 CLIP 是什么？除了 CLIP，对比学习还有哪些 case？</li>
<li>🔸 对比学习是否就是增强对角线元素、降低其他位置的值？</li>
<li>🔸 Modality Encoder 的输出是否就是 embedding？embedding 长度不一致所以需要 projector 吗？</li>
<li>🔸 其他模态的 signal token Sₓ 是什么？公式是什么意思？</li>
<li>🔸 MM IT（Instruction Tuning）是什么？</li>
<li>🔹 RLHF 之外还有哪些强化学习类型？</li>
<li>🔸 GAN 和 Multi-Agent RL 是否有关？</li>
<li>🔺 Transformer encoder-decoder 与 decoder-only 架构的归纳假设区别是什么？能否在算力和数据加持下用更简单的架构实现？</li>
<li>🔹 GPT-4V 是什么？</li>
<li>🔺 是否存在不是文本为中心，而是信号为核心的 MMLLM？</li>
</ol>
<hr>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>基于上述产生的问题，经过查询资料和整理，形成下面的总结</p>
<h2 id="人工智能的整体认知"><a href="#人工智能的整体认知" class="headerlink" title="人工智能的整体认知"></a>人工智能的整体认知</h2><p>本部分主要介绍我当前对于人工智能的整体的认知。其中里面有很多还不是很清楚的内容，还需要经过实践的洗礼，不断的迭代升级。</p>
<h3 id="1-AI的发展阶段"><a href="#1-AI的发展阶段" class="headerlink" title="1. AI的发展阶段"></a>1. AI的发展阶段</h3><table>
<thead>
<tr>
<th align="center">层次</th>
<th align="left">核心范式</th>
<th align="left">智能特征</th>
<th align="left">推理形式</th>
<th align="left">代表方法&#x2F;模型</th>
<th align="left">哲学假设</th>
<th align="left">局限</th>
<th align="left">典型应用</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>统计AI</strong></td>
<td align="left">数据驱动（Pattern Learning）</td>
<td align="left">感知强、理解弱</td>
<td align="left">相关性 (Correlation)</td>
<td align="left">CNN, RNN, Transformer</td>
<td align="left">世界是统计模式的集合</td>
<td align="left">无法解释“为什么”</td>
<td align="left">图像识别、语音识别、NLP</td>
</tr>
<tr>
<td align="center"><strong>因果AI</strong></td>
<td align="left">模型驱动（Model Learning）</td>
<td align="left">能解释与预测</td>
<td align="left">干预 (Intervention)、反事实 (Counterfactual)</td>
<td align="left">Causal Graphs, SCM, Do-Calculus, Causal RL</td>
<td align="left">世界存在可描述的因果结构</td>
<td align="left">显式建模困难</td>
<td align="left">科学建模、决策支持</td>
</tr>
<tr>
<td align="center"><strong>交互式因果AI&#x2F;具身智能</strong></td>
<td align="left">环境交互（Embodied Learning）</td>
<td align="left">感知—行动一体化，具备直觉</td>
<td align="left">内隐因果 (Embodied Causality)</td>
<td align="left">具身智能体、世界模型、主动学习、自监督强化学习</td>
<td align="left">因果是行动中涌现的结构</td>
<td align="left">缺乏理论统一框架</td>
<td align="left">机器人、自主驾驶、交互体</td>
</tr>
<tr>
<td align="center">从表格中，我们能感受到AI越来越强调因果，强调逻辑，实现可解释性</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
<h3 id="2-AI的智能层级框架"><a href="#2-AI的智能层级框架" class="headerlink" title="2. AI的智能层级框架"></a>2. AI的智能层级框架</h3><p>我们期望构建一个<strong>正交、形式化、可解释</strong>的智能层级框架，以覆盖主流模型与方法</p>
<table>
<thead>
<tr>
<th>智能层级</th>
<th>核心问题</th>
<th>优化目标</th>
<th>数学对象</th>
<th>典型能力</th>
<th>对应 Pearl 因果之梯</th>
<th>智能</th>
<th>多模态领域下的解释</th>
</tr>
</thead>
<tbody><tr>
<td><strong>L1:关联（Seeing）</strong></td>
<td>“看到什么？”<br>变量间有何统计关联？</td>
<td>最小化预测误差</td>
<td>联合分布 $P(X_1, \dots, X_n)$ 或条件分布 $P(Y \mid X)$</td>
<td>模式识别、分类、预测</td>
<td>Seeing（观察）</td>
<td>感知</td>
<td>不同模态信息之间的关联性</td>
</tr>
<tr>
<td><strong>L2：生成（Imaging）</strong></td>
<td>“世界如何被构造？”<br>数据如何被生成？</td>
<td>最大似然或匹配分布</td>
<td>生成机制 $P(X) &#x3D; \int P(X \mid Z) P(Z) , dZ$，或隐变量模型</td>
<td>模拟、补全、想象、反事实推理</td>
<td>Imagining（反事实）</td>
<td>想象</td>
<td>跨模态生成与补全</td>
</tr>
<tr>
<td><strong>L3:干预(Doing)</strong></td>
<td>“如果我做某事，会发生什么？”<br>行动如何改变结果？</td>
<td>最大化干预下的期望回报</td>
<td>干预分布$ P(Y \mid \text{do}(X &#x3D; x))$，策略 $\pi(a \mid s)$</td>
<td>决策、控制、优化、实验设计</td>
<td>Doing（干预）</td>
<td>行动</td>
<td>跨模态策略与因果干预</td>
</tr>
<tr>
<td><strong>L4:表示(Abstracting)</strong></td>
<td>“世界的不变结构是什么？”<br>如何提取可迁移的语义？</td>
<td>提取不变、解耦、稀疏表示</td>
<td>不变特征映射 $\phi: X \to Z$，满足 $I(Z; Y) \gg I(X; Y)$ 且对扰动鲁棒</td>
<td>泛化、迁移、解耦、抽象（元认知能力）</td>
<td></td>
<td>抽象</td>
<td>跨模态不变语义空间构建</td>
</tr>
</tbody></table>
<p><em>形式化:统一框架下的建模</em><br>$$<br>\min_{f,\phi,\pi,g}\underbrace{\mathcal{L}<em>{\mathrm{assoc}}\left(f\circ\phi\right)}</em>{\mathrm{L1}}+\lambda_{1}\underbrace{\mathcal{L}<em>{\mathrm{gen}}\left(g,\phi\right)}</em>{\mathrm{L2}}+\lambda_{2}\underbrace{\mathcal{L}<em>{\mathrm{interv}}\left(\pi,f,g\right)}</em>{\mathrm{L3}}+\lambda_{3}\underbrace{\mathcal{R}<em>{\mathrm{rep}}\left(\phi\right)}</em>{\mathrm{L4}}<br>$$</p>
<p>$$<br> \begin{aligned}<br> &amp; \text{其中:} \<br> &amp; \bullet\quad\phi:\text{表示编码器(L}4) \<br> &amp; \bullet\quad f:\text{判别头(L}1) \<br> &amp; \bullet\quad g:\text{生成解码器(L2}) \<br> &amp; \bullet\quad\pi:\text{策略网络(L3}) \<br> &amp; \bullet\quad\mathcal{R}_{\mathrm{rep}}:\text{表示正则项(如不变性、稀疏性、解耦性})<br> \end{aligned}<br>$$<br><em>注意</em></p>
<ul>
<li><strong>建模范式是多维的</strong>，一个模型可同时属于多个范式。</li>
<li><strong>归纳偏置是模型泛化的关键</strong>，不同结构隐含不同世界假设。</li>
<li><strong>从关联 → 生成 → 干预 → 抽象</strong>，是智能建模的演进路径。</li>
<li><strong>统一框架</strong>有助于设计下一代通用人工智能系统（如具身多模态 Agent）<br><em>具身智能</em><br>具身智能是指智能体通过<strong>与物理环境持续交互</strong>、利用其<strong>身体结构、感知能力与行动机制</strong>，在<strong>感知—行动闭环</strong>中产生、适应与优化智能行为的系统。</li>
</ul>
<h3 id="3-自顶而下的智能框架"><a href="#3-自顶而下的智能框架" class="headerlink" title="3. 自顶而下的智能框架"></a>3. 自顶而下的智能框架</h3><div class="code-container" data-rel="Mathematica"><figure class="iseeu highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">本体论层面（最高阶）</span><br><span class="line">└─ 问题本质：智能学习的任务是什么？</span><br><span class="line">   ├─ 表征世界 <span class="punctuation">(</span><span class="variable">Representation</span><span class="punctuation">)</span> → 如何编码信息？</span><br><span class="line">   ├─ 预测世界 <span class="punctuation">(</span><span class="variable">Prediction</span><span class="punctuation">)</span> → 能否从已知推测未知？</span><br><span class="line">   └─ 行动世界 <span class="punctuation">(</span><span class="variable">Action</span><span class="punctuation">)</span> → 能否通过行动改变未来？</span><br><span class="line"></span><br><span class="line">世界观层面（一阶抽象）</span><br><span class="line">└─ 问题本质：如何理解世界的生成与交互机制？</span><br><span class="line">	└─ 规则世界观 → 世界有边界规律（分类<span class="operator">/</span>回归）</span><br><span class="line">	└─ 生成世界观 → 世界是分布生成的（采样<span class="operator">/</span>生成）</span><br><span class="line">	└─ 干预世界观 → 世界可交互可干预（因果<span class="operator">/</span>强化）</span><br><span class="line"></span><br><span class="line">范式层面（二阶抽象）</span><br><span class="line">└─ 问题本质：如何形式化学习目标与结构假设？</span><br><span class="line">	├─ 判别式建模</span><br><span class="line">	├─ 生成式建模</span><br><span class="line">	├─ 序列建模</span><br><span class="line">	├─ 表示学习</span><br><span class="line">	├─ 对比学习</span><br><span class="line">	├─ 因果建模</span><br><span class="line">	└─ 强化学习</span><br><span class="line"></span><br><span class="line">架构与算法层面（三阶）</span><br><span class="line">└─ 问题本质：如何设计可计算的函数逼近器？</span><br><span class="line">	├─ <span class="variable">CNN</span></span><br><span class="line">	├─ <span class="variable">RNN</span></span><br><span class="line">	├─ <span class="variable">Transformer</span></span><br><span class="line">	├─ <span class="variable">Diffusion</span></span><br><span class="line">	├─ <span class="variable">GNN</span></span><br><span class="line">	└─ <span class="variable">MoE</span></span><br><span class="line"></span><br><span class="line">工程实践层面（最底层）</span><br><span class="line">└─ 问题本质：如何在现实约束下优化性能？</span><br><span class="line">	├─ 数据增强</span><br><span class="line">	├─ 预训练<span class="operator">-</span>微调范式</span><br><span class="line">	├─ <span class="variable">RLHF</span> <span class="operator">/</span> 人类反馈对齐</span><br><span class="line">	└─ 分布外鲁棒性</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>


<h3 id="4-常见建模范式（Modeling-Paradigms）的分类"><a href="#4-常见建模范式（Modeling-Paradigms）的分类" class="headerlink" title="4. 常见建模范式（Modeling Paradigms）的分类"></a>4. 常见建模范式（Modeling Paradigms）的分类</h3><p>建模范式是从不同维度对机器学习与人工智能模型进行抽象和分类的方式。单一模型往往同时属于多个范式（如 BERT 既是自监督、Transformer 结构、判别式、文本模态、Seq2Seq 框架下的语言模型）。下表从 <strong>六个正交维度</strong> 对主流范式进行划分：</p>
<table>
<thead>
<tr>
<th align="center">划分维度</th>
<th align="center">范式类别</th>
<th align="center">典型方法 &#x2F; 模型</th>
<th align="center">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>学习监督方式</strong></td>
<td align="center">监督学习</td>
<td align="center">Logistic Regression, ResNet, BERT</td>
<td align="center">输入输出对明确，有标签<br> 目标是拟合标签（分类、回归）</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">无监督学习</td>
<td align="center">K-means, PCA, Autoencoder</td>
<td align="center">只靠输入数据学习结构（聚类、降维、密度估计、自编码器）</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">自监督学习</td>
<td align="center">Masked LM (BERT), SimCLR, MoCo</td>
<td align="center">用数据自身构造伪任务（掩码预测、对比学习、下一个 token 预测）无标签</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">半监督学习</td>
<td align="center">MixMatch, Semi-BERT</td>
<td align="center">小量标注 + 大量无标签</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">强化学习</td>
<td align="center">DQN, PPO, AlphaGo</td>
<td align="center">交互环境 + 奖励信号</td>
</tr>
<tr>
<td align="center"><strong>输入输出关系</strong></td>
<td align="center">点到点 (Point2Point)</td>
<td align="center">线性回归、MLP 分类</td>
<td align="center">单个输入 → 单个输出（x → y）</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">序列到点 (Seq2One)</td>
<td align="center">LSTM 做情感分类、Transformer 分类头</td>
<td align="center">输入序列 → 一个结果</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">序列到序列 (Seq2Seq)</td>
<td align="center">Transformer MT, T5, Whisper</td>
<td align="center">输入序列 → 输出序列</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">多模态到序列</td>
<td align="center">CLIP, Flamingo, GPT-4V</td>
<td align="center">图像&#x2F;信号 + 文本 → 序列</td>
</tr>
<tr>
<td align="center"><strong>模型结构 &#x2F; 归纳偏置</strong></td>
<td align="center">线性模型</td>
<td align="center">Linear Regression, Logistic</td>
<td align="center">无深度结构<br> 决策边界为超平面，特征线性组合</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">树模型</td>
<td align="center">Decision Tree, XGBoost</td>
<td align="center">常用于 tabular 数据<br>  分段常数、特征重要性、可解释性强</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">神经网络模型</td>
<td align="center">CNN(AlexNet, ResNet)</td>
<td align="center">擅长图像建模<br> <strong>局部性 + 平移不变性</strong>：邻近像素相关，模式可平移复用</td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center">RNN(LSTM, GRU)</td>
<td align="center">早期序列建模<br><strong>时序依赖 + 递归状态</strong>：当前输出依赖历史状态</td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center">Transformer(GPT, BERT, ViT)</td>
<td align="center">当前主流序列&#x2F;多模态<br> <strong>全局依赖 + 并行注意力</strong>：任意 token 可交互，无位置限制</td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center">GNN(GCN, GraphSAGE)</td>
<td align="center">图结构建模<br><strong>图结构传播</strong>：节点信息通过邻居聚合</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">概率图模型</td>
<td align="center">HMM, CRF, Bayes Net</td>
<td align="center">统计建模<br> 显式建模变量间条件依赖关系</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">物理先验模型</td>
<td align="center">PINN（Physics-Informed Neural Network）</td>
<td align="center">融合物理定律作为约束</td>
</tr>
<tr>
<td align="center"><strong>优化目标 &#x2F; 损失</strong></td>
<td align="center">分类损失</td>
<td align="center">Cross-Entropy,Focal Loss</td>
<td align="center">监督分类(图像分类，文本分类)</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">回归损失</td>
<td align="center">MSE, MAE,Huber Loss</td>
<td align="center">监督回归(房价预测，目标检测坐标回归)</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">生成损失</td>
<td align="center">GAN Loss, Diffusion Loss,ELBO(变分推断)</td>
<td align="center">数据生成(图像生成、文本生成)</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">对比损失</td>
<td align="center">InfoNCE, Triplet Loss</td>
<td align="center">表示学习、多模态对齐</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">RL 损失</td>
<td align="center">Policy Gradient, Q-Learning</td>
<td align="center">强化学习(游戏AI,机器人控制)</td>
</tr>
<tr>
<td align="center"><strong>数据模态 &#x2F; 领域</strong></td>
<td align="center">文本</td>
<td align="center">GPT, BERT,T5</td>
<td align="center">语言模型: 语言建模、理解、生成</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">图像</td>
<td align="center">ResNet, ViT, Stable Diffusion</td>
<td align="center">视觉模型:分类、检测、生成、分割</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">音频&#x2F;语音</td>
<td align="center">Wav2Vec2, Whisper, TTS</td>
<td align="center">语音识别&#x2F;合成: ASR、TTS、语音情感识别</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">信号</td>
<td align="center">RadarNet, EEGNet</td>
<td align="center">通信、脑机接口</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">图结构</td>
<td align="center">GCN, GraphSAGE</td>
<td align="center">知识图谱、分子性质预测、推荐系统</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">多模态</td>
<td align="center">CLIP, Flamingo, MM-LLM</td>
<td align="center">跨模态对齐、检索、生成、推理</td>
</tr>
<tr>
<td align="center"><strong>学习&#x2F;推理方式</strong></td>
<td align="center">判别式</td>
<td align="center">Logistic Regression, BERT</td>
<td align="center">直接学习决策边界</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">生成式</td>
<td align="center">GPT, Diffusion, VAE</td>
<td align="center">建模数据分布并能采样</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">能量模型</td>
<td align="center">EBMs, Score Matching</td>
<td align="center">通过能量函数建模概率</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">对比学习</td>
<td align="center">SimCLR, CLIP</td>
<td align="center">通过相似性最大化构造表征空间</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">元学习</td>
<td align="center">MAML, ProtoNet</td>
<td align="center">学习如何学习</td>
</tr>
<tr>
<td align="center"><strong>输出任务</strong></td>
<td align="center">判别任务</td>
<td align="center">分类、回归</td>
<td align="center">输出类别&#x2F;数值(分类,回归)</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">生成任务</td>
<td align="center">文本生成、图像生成、信号生成</td>
<td align="center">输出新样本</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">检索任务</td>
<td align="center">CLIP embedding 检索</td>
<td align="center">输出相关样本</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">预测任务</td>
<td align="center">时间序列预测、轨迹预测</td>
<td align="center">输出未来值</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">控制任务</td>
<td align="center">机器人控制、RL</td>
<td align="center">输出动作</td>
</tr>
</tbody></table>
<h3 id="5-常见模型的归纳假设"><a href="#5-常见模型的归纳假设" class="headerlink" title="5.常见模型的归纳假设"></a>5.常见模型的归纳假设</h3><p>归纳假设是为了为了在有限算力和有限数据量的条件下，让模型能够从有限样本推广到无线可能的情况下的先验知识。<br>例如: </p>
<ul>
<li>CNN 假设 <strong>局部性 + 平移不变性</strong> → 图像中附近像素更相关，模式在空间上可以重复出现。</li>
<li>RNN 假设 <strong>时序依赖</strong> → 序列中前后的元素有因果关系，信息随时间流动。</li>
<li>Transformer 假设 <strong>全局依赖 + 并行注意</strong> → 任意两个 token 可能相关，不必局限于邻近元素。</li>
</ul>
<table>
<thead>
<tr>
<th><strong>建模类型</strong></th>
<th><strong>核心假设</strong></th>
<th><strong>思维方式 &#x2F; 方法</strong></th>
<th><strong>典型示例</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>判别式建模</strong></td>
<td>输入空间存在相对光滑、可分的决策边界</td>
<td>学习映射 (f(x) \to y)，关注类别可分性，不关心生成过程</td>
<td>逻辑回归、SVM、BERT（分类任务）</td>
</tr>
<tr>
<td><strong>生成式建模</strong></td>
<td>数据来自潜在分布，可通过模型重现</td>
<td>学习 (p(x)) 或 (p(y))，关注生成规律</td>
<td></td>
</tr>
<tr>
<td><strong>序列建模</strong></td>
<td>数据点有顺序，当前状态依赖历史</td>
<td>递推（RNN）、自注意力（Transformer）等编码依赖关系</td>
<td>语音建模、时间序列预测、语言建模</td>
</tr>
<tr>
<td><strong>对比式 &#x2F; 表示学习</strong></td>
<td>语义相近数据在潜在空间靠近，语义不相关远离</td>
<td>学习 embedding 空间，使相似性度量自然</td>
<td>SimCLR、CLIP、多模态对齐</td>
</tr>
<tr>
<td><strong>强化学习</strong></td>
<td>数据由交互生成，存在状态转移和奖励</td>
<td>最大化累积收益，而非拟合分布</td>
<td>AlphaGo、机器人控制</td>
</tr>
<tr>
<td><strong>因果建模</strong></td>
<td>统计相关性背后存在因果结构</td>
<td>构建结构方程模型 (SEM) 或通过干预推理</td>
<td>因果图模型、Do-calculus 应用于医疗&#x2F;经济预测</td>
</tr>
</tbody></table>
<h3 id="6-Seq2Seq-的工作和信号到信号的工作的区别"><a href="#6-Seq2Seq-的工作和信号到信号的工作的区别" class="headerlink" title="6. Seq2Seq 的工作和信号到信号的工作的区别"></a>6. Seq2Seq 的工作和信号到信号的工作的区别</h3><table>
<thead>
<tr>
<th align="center"><strong>维度</strong></th>
<th align="left"><strong>Seq2Seq（序列到序列）</strong></th>
<th align="left"><strong>Signal-to-Signal（信号到信号）</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>定义</strong></td>
<td align="left">输入一个序列，输出另一个序列</td>
<td align="left">输入一个原始信号序列，输出另一个信号序列</td>
</tr>
<tr>
<td align="center"><strong>典型任务</strong></td>
<td align="left">- 机器翻译（英语句子 → 中文句子）<br>- 自动摘要（长文档 → 短文摘要）<br>- 语音识别（音频特征序列 → 文本序列）</td>
<td align="left">- 音频增强（有噪音音频 → 干净音频）<br>- 语音合成（语音特征 → 波形）<br>- 无线通信（接收端信号 → 去噪&#x2F;解码信号）<br>- 脑电跨模态（EEG → fNIRS）</td>
</tr>
<tr>
<td align="center"><strong>特点</strong></td>
<td align="left">- 输入&#x2F;输出均为“序列”，模态可不同（文字、语音特征、动作编码等）<br>- 强调 <strong>时序结构</strong> 与 <strong>条件生成</strong></td>
<td align="left">- 输入&#x2F;输出通常为相同或相似模态（都是信号）<br>- 强调 <strong>保真度、信号还原、物理约束</strong></td>
</tr>
<tr>
<td align="center"><strong>范式 &#x2F; 应用关系</strong></td>
<td align="left">一种 <strong>建模范式</strong>（适用于任何序列 → 序列的任务）</td>
<td align="left">属于 <strong>具体应用场景</strong>，通常在 <strong>Seq2Seq 框架下实现</strong>，只是输入&#x2F;输出都是真实信号</td>
</tr>
</tbody></table>
<h3 id="7-Seq2Seq-框架下常见任务"><a href="#7-Seq2Seq-框架下常见任务" class="headerlink" title="7. Seq2Seq 框架下常见任务"></a>7. Seq2Seq 框架下常见任务</h3><div class="code-container" data-rel="Mathematica"><figure class="iseeu highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">Seq2Seq</span> 框架 <span class="punctuation">(</span>序列输入 → 序列输出<span class="punctuation">)</span></span><br><span class="line">├─ <span class="punctuation">(</span><span class="variable">a</span><span class="punctuation">)</span> 文本相关</span><br><span class="line">│   ├─ 机器翻译：英文句子 → 中文句子</span><br><span class="line">│   ├─ 文本摘要：长文本 → 短摘要</span><br><span class="line">│   ├─ 对话生成：对话历史 → 下一句回复</span><br><span class="line">│</span><br><span class="line">├─ <span class="punctuation">(</span><span class="variable">b</span><span class="punctuation">)</span> 语音 <span class="operator">/</span> 音频相关</span><br><span class="line">│   ├─ 语音识别 <span class="punctuation">(</span><span class="variable">ASR</span><span class="punctuation">)</span>：音频序列 → 文本序列</span><br><span class="line">│   ├─ 语音合成 <span class="punctuation">(</span><span class="variable">TTS</span><span class="punctuation">)</span>：文本 → 语音波形</span><br><span class="line">│   ├─ 语音增强 <span class="punctuation">(</span><span class="variable">Speech</span> <span class="variable">Enhancement</span><span class="punctuation">)</span>：带噪音音频 → 干净音频</span><br><span class="line">│</span><br><span class="line">├─ <span class="punctuation">(</span><span class="variable">c</span><span class="punctuation">)</span> 视觉相关</span><br><span class="line">│   ├─ 图像描述 <span class="punctuation">(</span><span class="built_in">Image</span> <span class="variable">Captioning</span><span class="punctuation">)</span>：图像特征序列 → 文本序列</span><br><span class="line">│   ├─ 视频字幕生成：视频帧序列 → 文本</span><br><span class="line">│</span><br><span class="line">├─ <span class="punctuation">(</span><span class="variable">d</span><span class="punctuation">)</span> 信号相关</span><br><span class="line">│   ├─ 无线信号解码：接收信号序列 → 原始比特序列</span><br><span class="line">│   ├─ 跨模态信号转换：<span class="variable">EEG</span> 信号 → 语音；雷达信号 → 图像</span><br><span class="line">│   ├─ 时序预测：过去信号序列 → 未来信号序列（天气、股价预测）</span><br><span class="line">│</span><br><span class="line">└─ <span class="punctuation">(</span><span class="variable">e</span><span class="punctuation">)</span> 跨模态任务</span><br><span class="line">    ├─ 语音翻译：语音序列 → 不同语言的文本序列</span><br><span class="line">    ├─ 手势识别：<span class="variable">IMU</span> 序列 → 动作类别</span><br><span class="line">    └─ <span class="variable">IoT</span> 多模态感知：传感器信号序列 → 行为标签 <span class="operator">/</span> 语音 <span class="operator">/</span> 图像</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>


<h2 id="单模态基础模型的常见知识点"><a href="#单模态基础模型的常见知识点" class="headerlink" title="单模态基础模型的常见知识点"></a>单模态基础模型的常见知识点</h2><p>单模态基础模型是指”<strong>只处理单一模态数据</strong> 的大模型”,包含”语言单模态”，“视觉单模态”，“音频单模态”模型</p>
<h3 id="LLM-的-zero-shot-和-ICL-能力"><a href="#LLM-的-zero-shot-和-ICL-能力" class="headerlink" title="LLM 的 zero-shot 和 ICL 能力"></a>LLM 的 zero-shot 和 ICL 能力</h3><blockquote>
<p>原文”LLM 具有良好的语言生成，zero-shot 和 ICL 的能力”</p>
</blockquote>
<table>
<thead>
<tr>
<th><strong>学习模式</strong></th>
<th><strong>定义</strong></th>
<th><strong>核心逻辑</strong></th>
<th><strong>示例</strong></th>
<th><strong>本质</strong></th>
<th><strong>多模态应用示例</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Zero-shot Learning (零样本学习)</td>
<td>在没有针对任务的专门训练样本下，直接完成任务</td>
<td>模型在预训练阶段学到的通用知识和映射规则，可迁移到新任务</td>
<td>翻译“apple → pomme”，VQA回答“How many apples on the table?”</td>
<td>预训练阶段学到的通用映射规则被迁移到新任务</td>
<td>多模态 LLM 在未见过的 VQA 或图像描述任务中直接推理</td>
</tr>
<tr>
<td>In-Context Learning (上下文学习, ICL)</td>
<td>在推理阶段通过上下文示例学习完成任务，无需更新模型权重</td>
<td>利用输入上下文的示例，进行模式匹配，模仿“输入→输出映射”</td>
<td>给 LLM 翻译示例：cat→chat, dog→chien, house→maison → tree？模型输出 arbre</td>
<td>LLM 充当上下文函数拟合器，利用上下文快速迁移</td>
<td>给多模态 LLM 几对 &lt;图像, caption&gt;，生成新图像的 caption，无需微调</td>
</tr>
</tbody></table>
<h3 id="LLM-中的预训练和指令微调"><a href="#LLM-中的预训练和指令微调" class="headerlink" title="LLM 中的预训练和指令微调"></a>LLM 中的预训练和指令微调</h3><table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>预训练 (Pre-training)</strong></th>
<th><strong>指令微调 (Instruction Tuning)</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>定义</strong></td>
<td>在大规模语料或多模态数据上进行通用任务训练，让模型获得广泛语言&#x2F;知识&#x2F;感知能力</td>
<td>在人工整理的任务指令数据上进行监督微调，使模型能理解并执行自然语言指令</td>
</tr>
<tr>
<td><strong>数据来源</strong></td>
<td>超大规模（互联网文本、图文对、视频字幕、音频转录等）</td>
<td>人工构造或过滤的高质量 (instruction, input, output) 三元组</td>
</tr>
<tr>
<td><strong>学习目标</strong></td>
<td>自监督学习（语言模型的 next-token prediction、图文对比学习、时间片段预测等）</td>
<td>监督学习（任务输入 → 输出）</td>
</tr>
<tr>
<td><strong>结果能力</strong></td>
<td>通才模型：语言理解、跨模态表示能力，通用知识</td>
<td>模型更“对话化”，能遵循指令完成具体任务</td>
</tr>
<tr>
<td><strong>数据规模</strong></td>
<td>TB 级</td>
<td>百万到千万级</td>
</tr>
<tr>
<td><strong>数据类型</strong></td>
<td>原始网络数据</td>
<td>人工清理过的任务数据</td>
</tr>
<tr>
<td><strong>类比</strong></td>
<td>上小学学“百科知识”</td>
<td>上辅导班学“答题技巧”</td>
</tr>
<tr>
<td><strong>典型例子</strong></td>
<td>GPT 系列、CLIP、Flamingo、BLIP-2</td>
<td>Alpaca、Vicuna、InstructGPT、LLaVA</td>
</tr>
</tbody></table>
<h2 id="多模态基础模型的常见知识点"><a href="#多模态基础模型的常见知识点" class="headerlink" title="多模态基础模型的常见知识点"></a>多模态基础模型的常见知识点</h2><h3 id="多模态模型的概要"><a href="#多模态模型的概要" class="headerlink" title="多模态模型的概要"></a>多模态模型的概要</h3><p>主流大模型主要集中在”视觉-语言”任务，评价体系也建立在大量视觉-语言benchmark。<br>“视觉-文本”任务的数据规模大，任务需求广。<br>信号模态由于缺少统一的benchmark和数据获取困难且任务场景分散从而研究得少<br>信号模态远比图像&#x2F;文本&#x2F;图像更要多样，分布涉及声学信号，电磁信号，生理信号，机械信号，环境信号，混合信号，多模态信号等</p>
<h3 id="多模态领域的benchmark"><a href="#多模态领域的benchmark" class="headerlink" title="多模态领域的benchmark"></a>多模态领域的benchmark</h3><p>Benchmark是一种公认的衡量体系(公认的数据集+评测任务形式+评价指标)。标准量化了模型的性能，便于不同研究之间的比较，推动发展。<br>例: 视觉-语言领域常见的benchmark</p>
<table>
<thead>
<tr>
<th><strong>任务&#x2F;数据集</strong></th>
<th><strong>输入</strong></th>
<th><strong>输出&#x2F;任务目标</strong></th>
<th><strong>任务形式</strong></th>
<th><strong>典型数据集</strong></th>
<th><strong>常用评价指标</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>VQAv2 (Visual Question Answering v2)</strong></td>
<td>一张图片 + 自然语言问题</td>
<td>模型回答问题（自然语言答案）</td>
<td><strong>判别 + 生成式问答</strong></td>
<td>VQAv2</td>
<td>Accuracy (整体&#x2F;开放式答案匹配)</td>
</tr>
<tr>
<td><strong>COCO Caption &#x2F; Flickr30k Captioning</strong></td>
<td>一张图片</td>
<td>生成自然语言描述</td>
<td><strong>生成式文本生成</strong></td>
<td>COCO Caption, Flickr30k</td>
<td>BLEU, METEOR, ROUGE, CIDEr, SPICE</td>
</tr>
<tr>
<td><strong>NLVR2 (Natural Language for Visual Reasoning 2)</strong></td>
<td>两张图片 + 一段文本</td>
<td>判断文本是否正确描述图片 (True&#x2F;False)</td>
<td><strong>判别式推理</strong></td>
<td>NLVR2</td>
<td>Accuracy</td>
</tr>
<tr>
<td><strong>RefCOCO &#x2F; RefCOCOg &#x2F; RefCOCO+</strong></td>
<td>一张图片 + 文本指令（目标描述）</td>
<td>在图片中定位目标物体（bounding box &#x2F; segmentation mask）</td>
<td><strong>定位&#x2F;检测任务</strong></td>
<td>RefCOCO, RefCOCOg, RefCOCO+</td>
<td>IoU (Intersection over Union), Accuracy</td>
</tr>
<tr>
<td><strong>ScienceQA &#x2F; TextVQA &#x2F; DocVQA</strong></td>
<td>图片（科学图表 &#x2F; 文档） + 文本问题</td>
<td>模型回答问题（自然语言答案）</td>
<td><strong>跨模态问答</strong></td>
<td>ScienceQA, TextVQA, DocVQA</td>
<td>Accuracy, Exact Match (EM)</td>
</tr>
<tr>
<td><strong>MMBench &#x2F; SEED-Bench &#x2F; LVLM-eHub</strong></td>
<td>多模态输入（图片&#x2F;文本等）</td>
<td>多任务统一测评（分类、问答、推理、描述等）</td>
<td><strong>综合基准评测</strong></td>
<td>MMBench, SEED-Bench, LVLM-eHub</td>
<td>多任务指标（Accuracy, BLEU, CIDEr, IoU 等，根据子任务）</td>
</tr>
</tbody></table>
<h3 id="MM-LLM的典型结构"><a href="#MM-LLM的典型结构" class="headerlink" title="MM-LLM的典型结构"></a>MM-LLM的典型结构</h3><div class="code-container" data-rel="Mathematica"><figure class="iseeu highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">输入模态  →  模态编码器<span class="punctuation">(</span>预处理特征<span class="punctuation">)</span>  </span><br><span class="line">          →  对齐模块<span class="punctuation">(</span><span class="built_in">Projection</span> <span class="operator">/</span> <span class="variable">Adapter</span> <span class="operator">/</span> <span class="variable">Attention</span><span class="punctuation">)</span>  </span><br><span class="line">          →  融合<span class="operator">/</span>交互模块<span class="punctuation">(</span><span class="variable">MM</span><span class="operator">-</span><span class="variable">Transformer</span> <span class="operator">/</span> <span class="built_in">Cross</span><span class="operator">-</span><span class="variable">Attn</span><span class="punctuation">)</span>  </span><br><span class="line">          →  <span class="variable">LLM</span> <span class="punctuation">(</span>语言推理<span class="operator">/</span>生成<span class="punctuation">)</span>  </span><br><span class="line">          →  下游任务输出</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>![[Pasted image 20251004181619.jpg]]</p>
<h4 id="Modality-Encoder"><a href="#Modality-Encoder" class="headerlink" title="Modality Encoder"></a>Modality Encoder</h4><ul>
<li>功能:<ul>
<li>编码不同模态的输入获取特征</li>
</ul>
</li>
<li>输出:<ul>
<li>不同维度，语音分布不一致、位置编码异构的embedding</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="center"><strong>模态类型</strong></th>
<th align="left"><strong>编码器名称</strong></th>
<th align="left"><strong>核心结构&#x2F;机制</strong></th>
<th align="left"><strong>训练范式</strong></th>
<th align="left"><strong>主要特征与优势</strong></th>
<th align="left"><strong>典型用途</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>视觉（图像）</strong></td>
<td align="left"><strong>NFNet-F6</strong></td>
<td align="left">无归一化的 ResNet 架构（No Normalization ResNet）</td>
<td align="left">有监督</td>
<td align="left">- 去掉 BatchNorm 提高数值稳定性- 在增强数据集上达 SOTA</td>
<td align="left">高精度图像分类</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>ViT (Vision Transformer)</strong></td>
<td align="left">将图像切分为 patch，经线性投影后输入 Transformer</td>
<td align="left">有监督 &#x2F; 自监督</td>
<td align="left">- 全局建模- 可迁移到下游任务</td>
<td align="left">图像识别、视觉编码</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>CLIP-ViT</strong></td>
<td align="left">ViT + 文本编码器；跨模态对比学习</td>
<td align="left">对比学习（Image-Text）</td>
<td align="left">- 学习视觉与语言的统一语义空间- 强大的零样本能力</td>
<td align="left">图文对齐、跨模态检索</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>EVA-CLIP ViT</strong></td>
<td align="left">对 CLIP 进行优化与扩展</td>
<td align="left">对比学习（Image-Text）</td>
<td align="left">- 稳定大规模 CLIP 训练- 提升视觉编码质量与鲁棒性</td>
<td align="left">大规模多模态预训练</td>
</tr>
<tr>
<td align="center"><strong>视觉（视频）</strong></td>
<td align="left">同上（统一采样约 5 帧）</td>
<td align="left">对视频帧进行与图像相同的编码处理</td>
<td align="left">—</td>
<td align="left">- 简化视频编码流程- 可迁移图像预训练模型</td>
<td align="left">视频理解、视频-文本对齐</td>
</tr>
<tr>
<td align="center"><strong>音频</strong></td>
<td align="left"><strong>C-Former</strong></td>
<td align="left">CIF（Continuous Integrate-and-Fire）对齐 + Transformer</td>
<td align="left">自监督 &#x2F; 弱监督</td>
<td align="left">- 实现时序对齐与序列建模- 精确时间同步</td>
<td align="left">语音识别、语音对齐</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>HuBERT</strong></td>
<td align="left">BERT 架构 + Mask 预测 + 隐单元离散化</td>
<td align="left">自监督</td>
<td align="left">- 利用未标注音频学习隐藏特征- 双向上下文建模</td>
<td align="left">语音表示学习</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>BEATs</strong></td>
<td align="left">双向音频 Transformer + 迭代式预训练</td>
<td align="left">自监督</td>
<td align="left">- 统一多任务音频表示- 高效迁移到多下游任务</td>
<td align="left">音频分类、事件检测</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>Whisper</strong></td>
<td align="left">Encoder-Decoder Transformer</td>
<td align="left">监督 &#x2F; 弱监督</td>
<td align="left">- 端到端语音识别 + 翻译- 多语言、多任务鲁棒性</td>
<td align="left">语音识别、语音翻译</td>
</tr>
</tbody></table>
<h4 id="Input-Projector"><a href="#Input-Projector" class="headerlink" title="Input Projector"></a>Input Projector</h4><ul>
<li>功能: 模态对齐<ul>
<li>把不同模态的特征对齐到LLM的embedding空间</li>
<li>保证输入到 LLM 的模态特征与文本 token embedding同维度、同分布</li>
</ul>
</li>
</ul>
<h4 id="LLM-Backbone"><a href="#LLM-Backbone" class="headerlink" title="LLM Backbone"></a>LLM Backbone</h4><ul>
<li>功能:<ul>
<li>以语言为核心进行跨模态的理解和推理，以及最后的输出</li>
</ul>
</li>
</ul>
<h4 id="Output-Projector"><a href="#Output-Projector" class="headerlink" title="Output Projector"></a>Output Projector</h4><ul>
<li>功能:<ul>
<li>把LLM的输出token embedding 转化为目标模态的特征空间</li>
<li>如果任务是 <strong>跨模态生成</strong>，比如“文字 → 图像”，必须有输出 Projector</li>
</ul>
</li>
</ul>
<h4 id="Modality-Generator"><a href="#Modality-Generator" class="headerlink" title="Modality Generator"></a>Modality Generator</h4><ul>
<li>功能:<ul>
<li>生成不同的模态作为输出</li>
</ul>
</li>
</ul>
<h4 id="归纳假设"><a href="#归纳假设" class="headerlink" title="归纳假设"></a>归纳假设</h4><ol>
<li><strong>模态独立假设</strong>（Modality-specific representations）<ul>
<li>每种模态（图像、视频、音频）都有其专门的 Encoder 来学习表示 → 假设不同模态需要独立的表征空间。</li>
</ul>
</li>
<li><strong>表征可对齐假设</strong>（Alignable representations）<ul>
<li>经过 <strong>Input Projector</strong>（比如 MLP、Cross-Attention、Q-Former），不同模态的表示可以投影&#x2F;对齐到一个共享语义空间 → 假设所有模态都能在统一的语义空间里交流。</li>
</ul>
</li>
<li><strong>语言中心假设</strong>（Language as backbone）<ul>
<li>LLM Backbone 是整个智能的核心 → 假设语言是最好的“中介”来承载推理、理解、生成能力。</li>
</ul>
</li>
<li><strong>条件生成假设</strong>（Conditional generation）<ul>
<li>生成端依赖 <strong>Output Projector + 模态生成器 (MG_X)</strong>，即假设“任何模态都可以看作是语言条件下的条件生成”。</li>
</ul>
</li>
</ol>
<div class="code-container" data-rel="Mathematica"><figure class="iseeu highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">训练<span class="operator">:</span> 在训练过程中，通常<span class="operator">**</span>冻结 <span class="variable">LLM</span> <span class="variable">Backbone</span>、模态编码器与模态生成器<span class="operator">**</span>，仅训练投影模块（<span class="built_in">Input</span><span class="operator">/</span><span class="variable">Output</span> <span class="variable">Projector</span>）以实现<span class="operator">**</span>模态对齐<span class="operator">**</span>。</span><br></pre></td></tr></table></figure></div>
<h3 id="Embedding-Token-对齐"><a href="#Embedding-Token-对齐" class="headerlink" title="Embedding &amp; Token &amp; 对齐"></a>Embedding &amp; Token &amp; 对齐</h3><table>
<thead>
<tr>
<th>角度</th>
<th><strong>Token</strong></th>
<th><strong>Embedding</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>本质</strong></td>
<td>离散符号（symbol）</td>
<td>连续向量（vector）</td>
</tr>
<tr>
<td><strong>信息形式</strong></td>
<td>符号化信息（Symbolic）</td>
<td>几何化信息（Geometric）</td>
</tr>
<tr>
<td><strong>可解释性</strong></td>
<td>强（人类可读：词&#x2F;子词）</td>
<td>弱（语义分布在向量结构中）</td>
</tr>
<tr>
<td><strong>计算操作</strong></td>
<td>只能索引或判等（&#x3D;&#x3D;）</td>
<td>可进行点积、余弦相似度、线性变换等</td>
</tr>
<tr>
<td><strong>学习方式</strong></td>
<td>预定义（由 tokenizer 确定）</td>
<td>可学习（通过梯度优化得到）</td>
</tr>
<tr>
<td><strong>来源</strong></td>
<td>Tokenizer 输出（词表索引）</td>
<td>Embedding 层（投影为向量）</td>
</tr>
<tr>
<td><strong>是否可直接输入模型</strong></td>
<td>❌ 否（需映射为 embedding）</td>
<td>✅ 是（模型操作对象）</td>
</tr>
<tr>
<td><strong>可学习性</strong></td>
<td>固定</td>
<td>可学习</td>
</tr>
<tr>
<td><strong>CLIP 对齐的对象</strong></td>
<td>❌ 否</td>
<td>✅ 是（在语义空间对齐）</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>维度</th>
<th><strong>Token-level 对齐</strong></th>
<th><strong>Embedding-level 对齐</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>表示形式</strong></td>
<td>离散符号（symbolic）</td>
<td>连续向量（continuous）</td>
</tr>
<tr>
<td><strong>优化方式</strong></td>
<td>基于显式匹配（如 attention 对齐、region-word 对齐）</td>
<td>基于相似性度量（如余弦距离、对比学习）</td>
</tr>
<tr>
<td><strong>数据依赖</strong></td>
<td>需强标注（词 ↔ 区域）</td>
<td>弱标注即可（整体图 ↔ 文本描述）</td>
</tr>
<tr>
<td><strong>训练稳定性</strong></td>
<td>差（符号难以优化）</td>
<td>好（连续空间可微分）</td>
</tr>
<tr>
<td><strong>泛化能力</strong></td>
<td>弱（依赖具体模态结构）</td>
<td>强（依赖语义结构）</td>
</tr>
<tr>
<td><strong>代表模型</strong></td>
<td>ViLBERT, LXMERT（BERT + Faster R-CNN）</td>
<td>CLIP, ALIGN, BLIP-2, ImageBind</td>
</tr>
<tr>
<td><strong>难易程度</strong></td>
<td>🚫 难（高成本、低扩展）</td>
<td>✅ 容易（主流选择）</td>
</tr>
</tbody></table>
<h3 id="MM-LLM的预训练和指令微调"><a href="#MM-LLM的预训练和指令微调" class="headerlink" title="MM-LLM的预训练和指令微调"></a>MM-LLM的预训练和指令微调</h3><p>IT的主流范式</p>
<table>
<thead>
<tr>
<th>维度</th>
<th><strong>SFT（Supervised Fine-Tuning）</strong></th>
<th><strong>RLHF（Reinforcement Learning with Human Feedback）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>中文名称</strong></td>
<td>监督微调</td>
<td>人类反馈强化学习</td>
</tr>
<tr>
<td><strong>核心目标</strong></td>
<td>学会遵循人类指令（Instruction Following）</td>
<td>学会符合人类偏好（Preference Alignment）</td>
</tr>
<tr>
<td><strong>数据来源</strong></td>
<td>人工标注的“指令 → 响应”对</td>
<td>人类对多候选输出的偏好打分</td>
</tr>
<tr>
<td><strong>优化思路</strong></td>
<td>直接最小化监督损失（如交叉熵）</td>
<td>间接最大化人类偏好（通过奖励模型）</td>
</tr>
<tr>
<td><strong>训练信号</strong></td>
<td>显式目标输出（Ground Truth）</td>
<td>奖励信号（Reward from preference）</td>
</tr>
<tr>
<td><strong>学习方式</strong></td>
<td>监督学习（Supervised Learning）</td>
<td>强化学习（Reinforcement Learning）</td>
</tr>
<tr>
<td><strong>典型流程</strong></td>
<td>模型输入(图像&#x2F;文本) → 生成 → 与人工答案对齐</td>
<td>模型生成多个输出 → 人类排序 → 奖励模型学习 → 优化策略</td>
</tr>
<tr>
<td><strong>典型算法&#x2F;方法</strong></td>
<td>Cross-Entropy Loss, Instruction Tuning</td>
<td>PPO (Proximal Policy Optimization), DPO</td>
</tr>
<tr>
<td><strong>代表模型阶段</strong></td>
<td>ChatGPT（SFT阶段）, LLaVA, BLIP-2</td>
<td>ChatGPT（RLHF阶段）, GPT-4, Gemini, Qwen2-VL</td>
</tr>
<tr>
<td><strong>优点</strong></td>
<td>稳定、简单、高效，易于扩展</td>
<td>提升模型价值对齐与人类偏好匹配度</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>易过拟合、缺乏灵活性</td>
<td>训练复杂、成本高、稳定性差</td>
</tr>
<tr>
<td><strong>简要例子</strong></td>
<td>给图像+问题 → 模型输出正确答案（GT）</td>
<td>给图像+指令 → 模型生成3个答案 → 人类选最优 → 奖励模型更新</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th><strong>阶段</strong></th>
<th><strong>任务类型</strong></th>
<th><strong>目标&#x2F;能力</strong></th>
<th><strong>示例</strong></th>
</tr>
</thead>
<tbody><tr>
<td>预训练 (Pre-training)</td>
<td>图文对 (Image-Text Pair)</td>
<td>学习视觉语义对应</td>
<td>CLIP、BLIP-2 预训练阶段</td>
</tr>
<tr>
<td></td>
<td>语音-文本对</td>
<td>学习语音识别、跨模态对齐</td>
<td>Whisper、Speech2Text 模型</td>
</tr>
<tr>
<td></td>
<td>视频-文本对</td>
<td>学习事件描述与时间序列理解</td>
<td>Video Captioning、Video-Language Pretraining</td>
</tr>
<tr>
<td>指令微调 (Instruction Tuning,IT)</td>
<td>图像 QA</td>
<td>模型学会根据图片回答问题</td>
<td>LLaVA、InstructBLIP</td>
</tr>
<tr>
<td></td>
<td>图像描述生成</td>
<td>根据图片生成自然语言描述</td>
<td>Flamingo、BLIP-2 指令阶段</td>
</tr>
<tr>
<td></td>
<td>多模态对话</td>
<td>模型能在对话中理解图像内容</td>
<td>Chat with Image 模型、LLaVA 对话场景</td>
</tr>
<tr>
<td></td>
<td>跨模态推理</td>
<td>根据图像生成代码、解释现象等</td>
<td>Visual Code Generation、科学图表解释任务</td>
</tr>
</tbody></table>
<h3 id="MM-LLM的系统性分类"><a href="#MM-LLM的系统性分类" class="headerlink" title="MM-LLM的系统性分类"></a>MM-LLM的系统性分类</h3><p>多模态大模型的目标就是让不同模态的信息在某种统一空间下实现交互。<br>本质都是实现<strong>模态对齐</strong><br><em>模态对齐模式分类</em></p>
<div class="code-container" data-rel="Mathematica"><figure class="iseeu highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">多模态对齐模式</span><br><span class="line">├── 显式模态对齐（<span class="variable">Explicit</span> <span class="built_in">Alignment</span>）</span><br><span class="line">│   ├── 预训练单模态模型 <span class="operator">+</span> 模态对齐</span><br><span class="line">│   ├── 模态适配器 <span class="punctuation">(</span><span class="variable">Adapter</span><span class="operator">-</span><span class="variable">based</span><span class="punctuation">)</span></span><br><span class="line">│   ├── 自监督跨模态学习（如 <span class="variable">CLIP</span>）</span><br><span class="line">│   └── 模态蒸馏 <span class="operator">/</span> 知识迁移（<span class="variable">Knowledge</span> <span class="variable">Distillation</span> <span class="operator">/</span> <span class="variable">Transfer</span>）</span><br><span class="line">│</span><br><span class="line">├── 隐式模态对齐（<span class="variable">Implicit</span> <span class="variable">Fusion</span>）<span class="operator">:</span>通过联合训练隐式学会对齐</span><br><span class="line">│   ├── 从头训练多模态模型</span><br><span class="line">│   └── 多阶段预训练（先模态内 → 再对齐 → 再任务）</span><br><span class="line">│</span><br><span class="line">├── 结构感知对齐（<span class="variable">Architecture</span><span class="operator">-</span><span class="variable">driven</span> <span class="operator">/</span> <span class="variable">Structural</span> <span class="built_in">Alignment</span>）<span class="operator">:</span> 强调语义单元而非整理表示</span><br><span class="line">│   ├── 模态 <span class="variable">MoE</span>（不同模态走不同 <span class="variable">expert</span> 分支，最后融合）</span><br><span class="line">│   └── 统一 <span class="variable">token</span> 化（<span class="variable">Modality</span> <span class="variable">Tokenization</span>，将模态离散为 <span class="variable">token</span>）</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p><em>模态对齐层级分类</em><br> 维度: 对齐粒度(granularity)+对齐手段(mechanism)</p>
<table>
<thead>
<tr>
<th>对齐层级</th>
<th>位置</th>
<th>目标</th>
<th>主要方法</th>
<th>典型示例 &#x2F; 工程手段</th>
</tr>
</thead>
<tbody><tr>
<td><strong>表示层对齐 (Representation-level Alignment)</strong></td>
<td>输入模态经过各自 encoder → 进入 LLM 前</td>
<td>将不同模态输入映射到同一语义空间</td>
<td>- <strong>共享编码空间</strong>：多模态输入分别编码后，约束 embedding 相似（如 CLIP 图像-文本对齐）<br>- <strong>跨模态对比学习</strong>：最大化正样本相似度，最小化负样本相似度<br>- <strong>投影变换 &#x2F; Adapter</strong>：通过 projection head 或模态适配器映射到主模型 embedding 空间</td>
<td>模态适配器（Adapter）、CLIP、对比学习框架</td>
</tr>
<tr>
<td><strong>结构层对齐 (Structural Alignment)</strong></td>
<td>模态 encoder 输出的“结构化特征”对齐（时间 &#x2F; 空间 &#x2F; 图结构）</td>
<td>对齐模态之间的关系结构(token,patch,frame等)，而不仅是单点 embedding-&gt;对齐语义单位</td>
<td>- <strong>时序对齐</strong>：对齐语音&#x2F;视频片段与文本 token（如强制对齐、DTW）<br>- <strong>空间对齐</strong>：对齐图像区域与文本 token（region-text grounding、DETR-based）<br>- <strong>图结构对齐</strong>：建模为图，通过 Graph Matching 或 GNN 对齐</td>
<td>DTW、DETR-based 区域对齐、GNN</td>
</tr>
<tr>
<td><strong>语义层对齐 (Semantic Alignment)</strong></td>
<td>融合之后，送入 LLM 或任务头之前</td>
<td>保证不同模态表达的语义概念一致</td>
<td>- <strong>生成式对齐</strong>：一个模态生成另一个模态，再反向验证一致性（text→image→text）<br>- <strong>知识对齐</strong>：利用外部知识库确保语义统一（WordNet、ConceptNet）<br>- <strong>任务驱动对齐</strong>：下游任务监督信号强制学习可迁移语义</td>
<td>Text-to-Image-to-Text consistency、知识图谱辅助对齐、下游任务监督</td>
</tr>
<tr>
<td><strong>优化层对齐 (Optimization-level Alignment)</strong></td>
<td>训练范式层面（影响整个 pipeline）</td>
<td>从训练&#x2F;优化角度保证不同模态学习的平衡与协同</td>
<td>- <strong>联合训练 + 多任务权重平衡</strong>（GradNorm、Dynamic Weight Averaging）<br>- <strong>互信息最大化</strong>（Deep InfoMax 风格）<br>- <strong>蒸馏式对齐</strong>：teacher-student 模态对齐</td>
<td>GradNorm、多任务训练、互信息最大化、模态蒸馏</td>
</tr>
<tr>
<td><strong>任务层对齐（Task-level Alignment）</strong></td>
<td>下游任务输出阶段</td>
<td>确保多模态输出在任务语义上一致（如 VQA 中图像推理与文本回答逻辑一致）</td>
<td>一致性损失、多任务联合训练、强化学习反馈</td>
<td>Video-LLaMA 中视频理解与问答一致性约束</td>
</tr>
</tbody></table>
<p><em>融合策略分类</em></p>
<table>
<thead>
<tr>
<th>融合方式</th>
<th>类别</th>
<th>思路</th>
<th>优点</th>
<th>缺点</th>
<th>典型例子</th>
</tr>
</thead>
<tbody><tr>
<td>**Early Fusion **</td>
<td>输入级融合</td>
<td>将多模态输入拼接后直接输入 Transformer</td>
<td>简单、直接</td>
<td>模态差异大时效果差</td>
<td>一些早期 VLP 模型</td>
</tr>
<tr>
<td>**Late Fusion **</td>
<td>输出级融合</td>
<td>模态各自独立编码，最后在高层融合结果</td>
<td>保留各模态独立性</td>
<td>缺乏深层交互</td>
<td>部分多模态检索模型</td>
</tr>
<tr>
<td><strong>Cross-Attention Fusion</strong></td>
<td>表示&#x2F;结构对齐后</td>
<td>一个模态作为 query，另一个模态作为 key&#x2F;value 做 cross-attention</td>
<td>能学到强交互</td>
<td>计算量大</td>
<td>BLIP-2 (Q-Former)、LLaVA</td>
</tr>
<tr>
<td><strong>Projection + Frozen LLM</strong></td>
<td>表示层对齐阶段</td>
<td>只训练轻量 projection（Adapter），将模态特征投影到 LLM embedding 空间，LLM 权重冻结</td>
<td>参数高效</td>
<td>对齐能力受限，语义对齐需大数据</td>
<td>LLaVA、MiniGPT-4、BLIP-2</td>
</tr>
<tr>
<td><strong>Unified Transformer</strong></td>
<td>全模态统一建模</td>
<td>所有模态都 token 化，统一输入到一个 Transformer</td>
<td>模态对称，语义一致</td>
<td>训练成本极高</td>
<td>Flamingo(<strong>统一输入空间</strong>:图像patch和文本token进行拼接)、Kosmos-1(统一语义空间但分离编码: 各自编码+注意力交互)、PaLM-E</td>
</tr>
<tr>
<td><strong>Mixture-of-Experts (MoE for Modalities)</strong></td>
<td>融合阶段 &#x2F; LLM 内部</td>
<td>不同模态通过 MoE 路由到不同专家，再在 LLM 中融合</td>
<td>可扩展新模态</td>
<td>调度复杂，优化难</td>
<td>DeepMind Gemini、部分 Google 最新工作</td>
</tr>
</tbody></table>
<p><em>训练模式分类</em></p>
<table>
<thead>
<tr>
<th><strong>训练模式</strong></th>
<th><strong>核心思路</strong></th>
<th><strong>优点</strong></th>
<th><strong>缺点</strong></th>
<th><strong>典型例子</strong></th>
<th><strong>适用场景&#x2F;备注</strong></th>
<th>解释</th>
<th>实现方式</th>
</tr>
</thead>
<tbody><tr>
<td><strong>预训练单模态模型 + 模态对齐</strong></td>
<td>利用已有单模态 backbone（如 CLIP 图像 encoder、GPT 文本 encoder），在联合表示空间对齐</td>
<td>计算效率高，充分利用已有模型知识</td>
<td>受限于原单模态模型的表示能力</td>
<td>BLIP-2, LLaVA</td>
<td>当已有强单模态模型时最优；适合快速原型</td>
<td>模态对齐: 把不同模态的特征放到一个<strong>共享表示空间</strong>中，让模型能“对齐”图像 ↔ 文本 ↔ 音频等</td>
<td>对比学习: CLIP: 让图像特征和文本特征尽量接近<br> 多模态Transformer: 同时输入不同模态特征，直接融合</td>
</tr>
<tr>
<td><strong>从头训练多模态模型</strong></td>
<td>直接训练 joint model，把不同模态一起学习</td>
<td>各模态表征天然统一，统一性强</td>
<td>训练代价大，数据需求高</td>
<td>Flamingo, PaLM-E</td>
<td>大规模数据和算力充足，追求最优联合表征</td>
<td>模型从零开始学习跨模态关联，无需依赖预训练单模态模型</td>
<td>联合输入多模态数据，通过统一架构（如 Transformer）进行联合训练</td>
</tr>
<tr>
<td><strong>模态适配器 &#x2F; 轻量调优 (Adapter-based)</strong></td>
<td>保持 LLM 不变，在输入端加小 adapter，把视觉&#x2F;音频&#x2F;信号映射到 embedding 空间</td>
<td>参数高效，不需大规模重训</td>
<td>Adapter 容量有限，难完全融合模态知识</td>
<td>LLaVA (linear projection), Q-Former (BLIP-2)</td>
<td>模型复用性强，小规模增量任务</td>
<td>模态适配器:在保持大语言模型结构不变的情况下，把非文本模态映射到 LLM 的输入 embedding 空间</td>
<td>- 简单线性投影 (LLaVA)。<br>    <br>- Q-Former（BLIP-2 里用小 Transformer 作为 adapter）</td>
</tr>
<tr>
<td><strong>多阶段预训练 (Stage-wise Pretraining)</strong></td>
<td>先做模态内预训练，再做模态间对齐，最后任务微调</td>
<td>逐步迁移，训练稳定</td>
<td>流程复杂</td>
<td>ALIGN, ALBEF</td>
<td>数据充足但算力有限时，保证训练稳定性</td>
<td>逐步构建跨模态理解能力，避免端到端训练的不稳定性</td>
<td>阶段1：图像&#x2F;文本分别预训练；阶段2：对比学习对齐；阶段3：下游任务微调</td>
</tr>
<tr>
<td><strong>模态蒸馏 &#x2F; 知识迁移</strong></td>
<td>利用强单模态教师模型，把知识蒸馏到多模态学生模型</td>
<td>学生模型小，推理快</td>
<td>学生性能受教师上限约束</td>
<td>Distilled CLIP, MiniGPT-4</td>
<td>想做轻量部署或推理高效模型</td>
<td>通过软标签或特征对齐，将教师模型的跨模态知识迁移到学生模型</td>
<td>特征蒸馏、logits 蒸馏、注意力迁移等</td>
</tr>
<tr>
<td><strong>模态 MoE (Mixture of Experts)</strong></td>
<td>不同模态输入走不同 expert 分支，最后融合</td>
<td>可扩展，每次只激活部分参数，节省计算</td>
<td>路由策略复杂，训练不稳定</td>
<td>GLaM-like 多模态扩展, Perceiver IO</td>
<td>面向大规模、多模态扩展任务</td>
<td>利用稀疏激活机制实现高效多模态建模</td>
<td>基于输入模态或内容动态选择 expert，加权融合结果</td>
</tr>
<tr>
<td><strong>统一 token 化 (Modality Tokenization)</strong></td>
<td>所有模态离散化为类似文本 token，然后直接用 LLM 处理</td>
<td>极端统一 → LLM 可直接处理多模态</td>
<td>信息损失大，对 tokenizer 依赖强</td>
<td>VQ-VAE + GPT, BEiT, MusicLM</td>
<td>模态高度异质但想用统一 LLM 架构</td>
<td>将非文本信号“翻译”成语言模型可理解的符号序列</td>
<td>使用 VQ-VAE、dVAE 等将图像&#x2F;音频编码为离散 token</td>
</tr>
<tr>
<td><strong>自监督跨模态学习</strong></td>
<td>利用海量未标注数据，通过对比&#x2F;掩码&#x2F;自回归预训练</td>
<td>不依赖标注，扩展性强</td>
<td>难以控制对齐质量</td>
<td>CLIP, BEiT-3</td>
<td>海量数据下对齐模态关系，适合预训练阶段</td>
<td>通过数据内在结构（如图文共现）学习语义对齐</td>
<td>• 对比学习（CLIP）  <br>• 掩码多模态建模（BEiT-3）  <br>• 跨模态自回归预测</td>
</tr>
</tbody></table>
<h3 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h3><ul>
<li>是否可以删除MMLLM的一些模块，简化假设？ 可以但是算力会增加很多(比如:所有模态都看作离散的token)</li>
<li>是否有信号为Backbone+文本为接口 的大模型？在信号处理领域，有把音频&#x2F;IQ信号&#x2F;时间序列作为核心的思路，但还不是主流。缺少统一的表达与交互语言。</li>
</ul>
<h2 id="ViT-Vision-Transformer"><a href="#ViT-Vision-Transformer" class="headerlink" title="ViT(Vision Transformer)"></a>ViT(Vision Transformer)</h2><table>
<thead>
<tr>
<th>项目</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>目的</strong></td>
<td>用 Transformer 机制替代 CNN 提升全局感知能力</td>
</tr>
<tr>
<td><strong>架构</strong></td>
<td>Patch Embedding → Transformer Encoder → MLP Head</td>
</tr>
<tr>
<td><strong>优点</strong></td>
<td>全局特征建模强、可扩展性好、迁移性优、解释性强</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>数据需求大、计算复杂、缺乏局部先验</td>
</tr>
<tr>
<td><strong>效果</strong></td>
<td>在大规模数据集上性能超越 CNN，成为视觉模型新主流</td>
</tr>
<tr>
<td>![[Pasted image 20251004182411.png]]</td>
<td></td>
</tr>
<tr>
<td>注: 如果 <strong>patch 切得过大</strong>，确实会 <strong>丢失局部的二维位置信息</strong></td>
<td></td>
</tr>
</tbody></table>
<h2 id="对比学习"><a href="#对比学习" class="headerlink" title="对比学习"></a>对比学习</h2><p>核心思想: <strong>拉近正样本对的表示距离，推远负样本对的表示距离</strong>，从而在嵌入空间中构造有意义的语义结构</p>
<h3 id="CLIP-Contrastive-Language-Image-Pretraining"><a href="#CLIP-Contrastive-Language-Image-Pretraining" class="headerlink" title="CLIP(Contrastive Language-Image Pretraining)"></a>CLIP(Contrastive Language-Image Pretraining)</h3><p>目标: 把图像和文本映射到同一个语义空间<br>机制: 对比学习</p>
<h3 id="常见应用"><a href="#常见应用" class="headerlink" title="常见应用"></a>常见应用</h3><table>
<thead>
<tr>
<th align="center"><strong>领域</strong></th>
<th align="left"><strong>代表方法</strong></th>
<th align="left"><strong>正样本定义</strong></th>
<th align="left"><strong>负样本来源</strong></th>
<th align="left"><strong>应用场景</strong></th>
<th align="left"><strong>主要创新与特点</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>计算机视觉 (CV)</strong></td>
<td align="left"><strong>SimCLR (2020, Google)</strong></td>
<td align="left">同一张图像的两次随机增强视图</td>
<td align="left">同一 batch 内其他图像</td>
<td align="left">无监督图像表征学习</td>
<td align="left">纯对比学习，无需标签；使用 InfoNCE 损失，结构简洁但性能强</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>MoCo (2020, Facebook)</strong></td>
<td align="left">同一图像的不同增强视图</td>
<td align="left">动量更新的负样本队列</td>
<td align="left">大规模图像表征、检测、分类</td>
<td align="left">引入动量编码器与队列机制，维持动态负样本库，提升训练稳定性</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>BYOL (2020, DeepMind)</strong></td>
<td align="left">同一图像的两种增强视图（Teacher–Student）</td>
<td align="left">无显式负样本</td>
<td align="left">自监督表征学习</td>
<td align="left">通过动量教师与停止梯度避免坍塌，去除对负样本依赖</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>SimSiam (2021, Meta)</strong></td>
<td align="left">同一图像的不同增强视图</td>
<td align="left">无显式负样本</td>
<td align="left">轻量级表征学习</td>
<td align="left">去掉动量教师，仅靠停止梯度维持稳定；结构更简洁</td>
</tr>
<tr>
<td align="center"><strong>自然语言处理 (NLP)</strong></td>
<td align="left"><strong>SimCSE (2021)</strong></td>
<td align="left">同一句子经不同 dropout 得到的两种结果</td>
<td align="left">Batch 内其他句子</td>
<td align="left">句子 embedding、语义检索</td>
<td align="left">对比学习提升句子表示语义一致性；方法极简高效</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>InfoXLM &#x2F; LaBSE</strong></td>
<td align="left">平行语料中的中英文句子</td>
<td align="left">其他句子</td>
<td align="left">跨语言语义对齐</td>
<td align="left">学到语言无关语义空间，用于跨语言检索与翻译</td>
</tr>
<tr>
<td align="center"><strong>语音 &#x2F; 音频 (Speech &amp; Audio)</strong></td>
<td align="left"><strong>Wav2Vec 2.0 (2020, Facebook)</strong></td>
<td align="left">被 mask 的语音片段 vs 预测 embedding</td>
<td align="left">负样本来自非目标帧</td>
<td align="left">语音识别、音频表征</td>
<td align="left">Mask + 对比预测；在低标注数据下表现优异</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>HuBERT (2021)</strong></td>
<td align="left">相同语音的不同 masked 区域预测</td>
<td align="left">其他 cluster 中样本</td>
<td align="left">语音表征、自监督 ASR</td>
<td align="left">结合聚类与预测任务，形成自监督标签；提升表征质量</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>CLAP (2022)</strong></td>
<td align="left">音频与对应文本描述</td>
<td align="left">其他音频或文本</td>
<td align="left">音频–文本跨模态检索</td>
<td align="left">类似 CLIP 的音频版本；实现听觉语义对齐与跨模态理解</td>
</tr>
<tr>
<td align="center"><strong>跨模态 (Multi-Modal)</strong></td>
<td align="left"><strong>CLIP (2021, OpenAI)</strong></td>
<td align="left">图像与对应文本说明</td>
<td align="left">其他图文对</td>
<td align="left">零样本分类、图文检索</td>
<td align="left">首次大规模图文对比预训练；双塔结构；强泛化与零样本能力</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>ALIGN (2021, Google)</strong></td>
<td align="left">图像与对应文本</td>
<td align="left">大规模网页数据中的负样本</td>
<td align="left">多模态检索、语义对齐</td>
<td align="left">使用上亿图文对，弱标注数据；高效大规模预训练</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>LiT (2022, Google)</strong></td>
<td align="left">冻结文本模型 + 匹配图像</td>
<td align="left">其他样本</td>
<td align="left">高效多模态对齐</td>
<td align="left">避免联合训练，仅调图像模型；快速迁移已有语言模型</td>
</tr>
<tr>
<td align="center"></td>
<td align="left"><strong>Audio–Video CL</strong></td>
<td align="left">视频帧与对应音频片段</td>
<td align="left">其他片段</td>
<td align="left">视频理解、跨模态检索</td>
<td align="left">捕捉声–视同步关系，学习时空跨模态表示</td>
</tr>
</tbody></table>
<h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><table>
<thead>
<tr>
<th><strong>类别</strong></th>
<th><strong>核心思路</strong></th>
<th><strong>代表算法</strong></th>
<th><strong>典型应用场景</strong></th>
<th>优缺点简述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>基于价值的方法 (Value-based RL)</strong></td>
<td>通过学习 <strong>状态-动作价值函数 Q(s,a)</strong> 来指导决策，选择期望回报最高的动作</td>
<td>Q-Learning、Deep Q-Network (DQN)</td>
<td>Atari 游戏（打乒乓、吃豆人等）</td>
<td>✅ 稳定高效，适合离散动作；❌ 难处理连续控制</td>
</tr>
<tr>
<td><strong>基于策略的方法 (Policy-based RL)</strong></td>
<td>直接学习策略 π(as)，通过优化期望回报来更新策略参数</td>
<td>REINFORCE</td>
<td></td>
<td>连续动作控制（机器人走路）</td>
</tr>
<tr>
<td><strong>Actor-Critic 方法（结合价值+策略）</strong></td>
<td>同时学习策略（Actor）和价值函数（Critic），相互指导提升稳定性</td>
<td>A3C、PPO、DDPG</td>
<td>自动驾驶决策、复杂运动控制</td>
<td>✅ 稳定性好；❌ 超参数多、调优复杂</td>
</tr>
<tr>
<td><strong>基于模型的方法 (Model-based RL)</strong></td>
<td>学习环境的动态模型，用模型进行 <strong>内部模拟（planning）</strong> 来提升效率</td>
<td>Dyna-Q、AlphaZero</td>
<td>围棋、国际象棋、规划控制</td>
<td>✅ 样本效率高；❌ 模型误差敏感</td>
</tr>
<tr>
<td><strong>层次化强化学习 (Hierarchical RL)</strong></td>
<td>将任务分解为多个子任务（高层规划、低层执行）</td>
<td>Options Framework、HRL</td>
<td>机器人执行多步复杂任务（如“走到桌子→抓起杯子”）</td>
<td>✅ 可扩展复杂任务；❌ 层次设计困难</td>
</tr>
<tr>
<td><strong>多智能体强化学习 (Multi-Agent RL)</strong></td>
<td>多个智能体同时学习与博弈，通过协作或竞争优化整体策略</td>
<td>MADDPG、QMIX</td>
<td>多无人机协作、群体智能、博弈系统</td>
<td>✅ 支持协作&#x2F;竞争；❌ 收敛困难、通信复杂</td>
</tr>
<tr>
<td><strong>基于人类反馈的强化学习 (RLHF)</strong></td>
<td>用人类偏好信号代替环境奖励，训练奖励模型指导策略优化</td>
<td>PPO（with reward model）、DPO</td>
<td>LLM &#x2F; MMLLM 的人类价值对齐（如 ChatGPT、Gemini、Qwen-VL）</td>
<td>✅ 能融入人类价值观；❌ 标注成本高、奖励偏差风险</td>
</tr>
</tbody></table>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[1]. 林夕. 《# 多模态大模型入门指南-长文慎入【持续更新】》<a class="link"   target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/682893729" >https://zhuanlan.zhihu.com/p/682893729<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br>[2].OpenAI-GPT-5<br>[3].Qwen3-Max<br>[4].Deepseek-V3.2</p>

		</div>

		
		<div class="post-copyright-info w-full my-8 px-2 sm:px-6 md:px-8">
			<div class="article-copyright-info-container">
    <ul>
        <li><strong>标题:</strong> 多模态大模型入门指南-阅读提问</li>
        <li><strong>作者:</strong> Ttzs</li>
        <li><strong>创建于
                :</strong> 2025-09-25 13:00:02</li>
        
            <li>
                <strong>更新于
                    :</strong> 2025-10-04 19:30:48
            </li>
        
        <li>
            <strong>链接:</strong> https://ttzs-git.github.io/2025/09/25/多模态大模型入门指南-阅读提问/
        </li>
        <li>
            <strong>
                版权声明:
            </strong>
            

            
                本文章采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a> 进行许可。
            
        </li>
    </ul>
</div>

		</div>
		

		
		<ul class="post-tags-box text-lg mt-1.5 flex-wrap justify-center flex md:hidden">
			
			<li class="tag-item mx-0.5">
				<a href="../../../../tags/%E7%BB%BC%E8%BF%B0/">#综述</a>&nbsp;
			</li>
			
		</ul>
		

		

		
		<div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8">
			
			<div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="prev" rel="prev" href="../template/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">
					<span class="left arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-left"></i>
					</span>
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">{{title}}</span>
						<span class="post-nav-item">上一篇</span>
					</span>
				</a>
			</div>
			
			
			<div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="next" rel="next" href="../CS25%20v4-Hyung%20Won%20Chung/">
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">CS25 v4-Hyung Won Chung</span>
						<span class="post-nav-item">下一篇</span>
					</span>
					<span class="right arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-right"></i>
					</span>
				</a>
			</div>
			
		</div>
		


		
		<div class="comment-container px-2 sm:px-6 md:px-8 pb-8">
			<div class="comments-container mt-10 w-full ">
    <div id="comment-anchor" class="w-full h-2.5"></div>
    <div class="comment-area-title w-full my-1.5 md:my-2.5 text-xl md:text-3xl font-bold">
        评论
    </div>
    

        
            
    <div id="giscus-container"></div>
    <script data-swup-reload-script defer>
        async function loadGiscus() {
            const giscusConfig = {
                'src': 'https://giscus.app/client.js',
                'data-repo': 'Ttzs-Git/talk',
                'data-repo-id': 'R_kgDOOPEOEg',
                'data-category': 'Announcements',
                'data-category-id': 'DIC_kwDOOPEOEs4Coe08',
                'data-mapping': 'pathname',
                'data-strict': '0',
                'data-reactions-enabled': '1',
                'data-emit-metadata': '1',
                'data-theme': 'preferred_color_scheme',
                'data-lang': 'zh-CN',
                'data-input-position': 'bottom',
                'data-loading': 'not-lazy',
                'crossorigin': 'anonymous',
                'async': true
            }
            const giscusScript = document.createElement('script');
            for (const key in giscusConfig) {
                giscusScript.setAttribute(key, giscusConfig[key]);
            }
            document.getElementById('giscus-container').appendChild(giscusScript);
        }
        if ('true') {
            let loadGiscusTimeout = setTimeout(() => {
                loadGiscus();
                clearTimeout(loadGiscusTimeout);
            }, 1000);
        } else {
            document.addEventListener('DOMContentLoaded', loadGiscus);
        }
    </script>


        
        
    
</div>

		</div>
		
	</div>

	
	<div class="toc-content-container">
		<div class="post-toc-wrap">
	<div class="post-toc">
		<div class="toc-title">目录</div>
		<div class="page-title">多模态大模型入门指南-阅读提问</div>
		<ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E6%B8%85%E5%8D%95"><span class="nav-number">2.</span> <span class="nav-text">问题清单</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">3.</span> <span class="nav-text">总结</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E6%95%B4%E4%BD%93%E8%AE%A4%E7%9F%A5"><span class="nav-number">3.1.</span> <span class="nav-text">人工智能的整体认知</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-AI%E7%9A%84%E5%8F%91%E5%B1%95%E9%98%B6%E6%AE%B5"><span class="nav-number">3.1.1.</span> <span class="nav-text">1. AI的发展阶段</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-AI%E7%9A%84%E6%99%BA%E8%83%BD%E5%B1%82%E7%BA%A7%E6%A1%86%E6%9E%B6"><span class="nav-number">3.1.2.</span> <span class="nav-text">2. AI的智能层级框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E8%87%AA%E9%A1%B6%E8%80%8C%E4%B8%8B%E7%9A%84%E6%99%BA%E8%83%BD%E6%A1%86%E6%9E%B6"><span class="nav-number">3.1.3.</span> <span class="nav-text">3. 自顶而下的智能框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E5%B8%B8%E8%A7%81%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%EF%BC%88Modeling-Paradigms%EF%BC%89%E7%9A%84%E5%88%86%E7%B1%BB"><span class="nav-number">3.1.4.</span> <span class="nav-text">4. 常见建模范式（Modeling Paradigms）的分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%92%E7%BA%B3%E5%81%87%E8%AE%BE"><span class="nav-number">3.1.5.</span> <span class="nav-text">5.常见模型的归纳假设</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-Seq2Seq-%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%92%8C%E4%BF%A1%E5%8F%B7%E5%88%B0%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">3.1.6.</span> <span class="nav-text">6. Seq2Seq 的工作和信号到信号的工作的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-Seq2Seq-%E6%A1%86%E6%9E%B6%E4%B8%8B%E5%B8%B8%E8%A7%81%E4%BB%BB%E5%8A%A1"><span class="nav-number">3.1.7.</span> <span class="nav-text">7. Seq2Seq 框架下常见任务</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%95%E6%A8%A1%E6%80%81%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="nav-number">3.2.</span> <span class="nav-text">单模态基础模型的常见知识点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LLM-%E7%9A%84-zero-shot-%E5%92%8C-ICL-%E8%83%BD%E5%8A%9B"><span class="nav-number">3.2.1.</span> <span class="nav-text">LLM 的 zero-shot 和 ICL 能力</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LLM-%E4%B8%AD%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E5%92%8C%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83"><span class="nav-number">3.2.2.</span> <span class="nav-text">LLM 中的预训练和指令微调</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="nav-number">3.3.</span> <span class="nav-text">多模态基础模型的常见知识点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%A6%82%E8%A6%81"><span class="nav-number">3.3.1.</span> <span class="nav-text">多模态模型的概要</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%86%E5%9F%9F%E7%9A%84benchmark"><span class="nav-number">3.3.2.</span> <span class="nav-text">多模态领域的benchmark</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MM-LLM%E7%9A%84%E5%85%B8%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">3.3.3.</span> <span class="nav-text">MM-LLM的典型结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Embedding-Token-%E5%AF%B9%E9%BD%90"><span class="nav-number">3.3.4.</span> <span class="nav-text">Embedding &amp; Token &amp; 对齐</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MM-LLM%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E5%92%8C%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83"><span class="nav-number">3.3.5.</span> <span class="nav-text">MM-LLM的预训练和指令微调</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MM-LLM%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%80%A7%E5%88%86%E7%B1%BB"><span class="nav-number">3.3.6.</span> <span class="nav-text">MM-LLM的系统性分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E9%97%AE%E9%A2%98"><span class="nav-number">3.3.7.</span> <span class="nav-text">其他问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ViT-Vision-Transformer"><span class="nav-number">3.4.</span> <span class="nav-text">ViT(Vision Transformer)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0"><span class="nav-number">3.5.</span> <span class="nav-text">对比学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CLIP-Contrastive-Language-Image-Pretraining"><span class="nav-number">3.5.1.</span> <span class="nav-text">CLIP(Contrastive Language-Image Pretraining)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8"><span class="nav-number">3.5.2.</span> <span class="nav-text">常见应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="nav-number">3.6.</span> <span class="nav-text">强化学习</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">4.</span> <span class="nav-text">参考</span></a></li></ol>

	</div>
</div>
	</div>
	
</div>
			</div>

			
		</div>

		<div class="main-content-footer">
			<footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
            <div class="customize-info my-1">Have a good time!</div>
        
        <div class="text-center">
            &copy;
            
              <span>2025</span>
              -
            
            2025&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Ttzs</a>
            
                
                <p class="post-count space-x-0.5">
                    <span>
                        共撰写了 16 篇文章
                    </span>
                    
                        <span>
                            共 16.2k 字
                        </span>
                    
                </p>
            
        </div>
        
            <script data-swup-reload-script src="https://cn.vercount.one/js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">访问人数</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">总访问量</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">由 <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a> 驱动</span>
            <span class="text-sm lg:block">主题&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.8.2</a></span>
        </div>
        
            <div class="icp-info my-1"><a target="_blank" rel="nofollow" href="
                
                    https://icp.gov.moe/?keyword=20256985
                
                ">萌ICP备20256985号</a></div>
        
        
            <div>
                博客已运行 <span class="odometer" id="runtime_days" ></span> 天 <span class="odometer" id="runtime_hours"></span> 小时 <span class="odometer" id="runtime_minutes"></span> 分钟 <span class="odometer" id="runtime_seconds"></span> 秒
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
		</div>
	</div>

	
	<div class="post-tools">
		<div class="post-tools-container">
	<ul class="article-tools-list">
		<!-- TOC aside toggle -->
		
		<li class="right-bottom-tools page-aside-toggle">
			<i class="fa-regular fa-outdent"></i>
		</li>
		

		<!-- go comment -->
		
		<li class="go-comment">
			<i class="fa-regular fa-comments"></i>
		</li>
		
	</ul>
</div>
	</div>
	

	<div class="right-side-tools-container">
		<div class="side-tools-container">
	<ul class="hidden-tools-list">
		<li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-plus"></i>
		</li>

		<li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-minus"></i>
		</li>

		<li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
			<i class="fa-regular fa-moon"></i>
		</li>

		<!-- rss -->
		

		

		<li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
			<i class="fa-regular fa-arrow-down"></i>
		</li>
	</ul>

	<ul class="visible-tools-list">
		<li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
			<i class="fa-regular fa-cog fa-spin"></i>
		</li>
		
		<li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
			<i class="arrow-up fas fa-arrow-up"></i>
			<span class="percent"></span>
		</li>
		
		
	</ul>
</div>
	</div>

	<div class="image-viewer-container">
	<img src="">
</div>

	
	<div class="search-pop-overlay">
	<div class="popup search-popup">
		<div class="search-header">
			<span class="search-input-field-pre">
				<i class="fa-solid fa-keyboard"></i>
			</span>
			<div class="search-input-container">
				<input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="站内搜索您需要的内容..." spellcheck="false" type="search" class="search-input">
			</div>
			<span class="popup-btn-close">
				<i class="fa-solid fa-times"></i>
			</span>
		</div>
		<div id="search-result">
			<div id="no-result">
				<i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i>
			</div>
		</div>
	</div>
</div>
	

</main>



<script src="js/build/libs/Swup.min.js"></script>

<script src="js/build/libs/SwupSlideTheme.min.js"></script>

<script src="js/build/libs/SwupScriptsPlugin.min.js"></script>

<script src="js/build/libs/SwupProgressPlugin.min.js"></script>

<script src="js/build/libs/SwupScrollPlugin.min.js"></script>

<script src="js/build/libs/SwupPreloadPlugin.min.js"></script>

<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>




	
<script src="js/build/tools/imageViewer.js" type="module"></script>

<script src="js/build/utils.js" type="module"></script>

<script src="js/build/main.js" type="module"></script>

<script src="js/build/layouts/navbarShrink.js" type="module"></script>

<script src="js/build/tools/scrollTopBottom.js" type="module"></script>

<script src="js/build/tools/lightDarkSwitch.js" type="module"></script>

<script src="js/build/layouts/categoryList.js" type="module"></script>



    
<script src="js/build/tools/localSearch.js" type="module"></script>




    
<script src="js/build/tools/codeBlock.js" type="module"></script>




    
<script src="js/build/layouts/lazyload.js" type="module"></script>




    
<script src="js/build/tools/runtime.js"></script>

    
<script src="js/build/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="assets/odometer-theme-minimal.css">




  
<script src="js/build/libs/Typed.min.js"></script>

  
<script src="js/build/plugins/typed.js" type="module"></script>






    
<script src="js/build/libs/minimasonry.min.js"></script>

    
<script src="js/build/plugins/masonry.js" type="module"></script>




    
<script src="js/build/libs/anime.min.js"></script>





    
<script src="js/build/tools/tocToggle.js" type="module" data-swup-reload-script=""></script>

<script src="js/build/layouts/toc.js" type="module" data-swup-reload-script=""></script>

<script src="js/build/plugins/tabs.js" type="module" data-swup-reload-script=""></script>




<script src="js/build/libs/moment-with-locales.min.js" data-swup-reload-script=""></script>


<script src="js/build/layouts/essays.js" type="module" data-swup-reload-script=""></script>





    
<script src="js/build/layouts/bookmarkNav.js" type="module"></script>


	
</body>

</html>